{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OIoVK-e2o_DY"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, BatchNormalization, GlobalAveragePooling2D, Input,MaxPool2D, Flatten\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import Adam, SGD,Nadam,AdamW,RMSprop\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.metrics import roc_curve, auc, confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wj0u17HPo_Db"
      },
      "outputs": [],
      "source": [
        "# Apply Cutout augmentation\n",
        "def apply_cutout(image, size=8, n_holes=1):\n",
        "    h, w = image.shape[0], image.shape[1]\n",
        "    for n in range(n_holes):\n",
        "        # Random position of cutout\n",
        "        y = np.random.randint(h)\n",
        "        x = np.random.randint(w)\n",
        "\n",
        "        # Ensure cutout stays within image bounds\n",
        "        y1 = np.clip(y - size // 2, 0, h)\n",
        "        y2 = np.clip(y + size // 2, 0, h)\n",
        "        x1 = np.clip(x - size // 2, 0, w)\n",
        "        x2 = np.clip(x + size // 2, 0, w)\n",
        "\n",
        "        # Set the cutout region to zero\n",
        "        image[y1:y2, x1:x2, :] = 0\n",
        "    return image\n",
        "\n",
        "# Apply cutout to training data\n",
        "x_train_ship_cutout = x_train_ship.copy()\n",
        "for i in range(len(x_train_ship_cutout)):\n",
        "    x_train_ship_cutout[i] = apply_cutout(x_train_ship_cutout[i])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rcM5mbYo_Dc",
        "outputId": "2ffbcdf4-9ae5-4400-c46b-ae6330712c9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Load CIFAR-10 data\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# ---- TRUCK vs NON-TRUCK ----\n",
        "# Prepare balanced dataset for truck (class 9) vs non-truck\n",
        "def prepare_binary_data(x, y, target_class):\n",
        "    pos_idx = np.where(y == target_class)[0]\n",
        "    neg_idx = np.where((y != target_class))[0]\n",
        "    n = min(len(pos_idx), len(neg_idx))\n",
        "    idx = np.concatenate([pos_idx[:n], np.random.choice(neg_idx, n, replace=False)])\n",
        "    np.random.shuffle(idx)\n",
        "    return x[idx].astype('float32') / 255.0, (y[idx] == target_class).astype(int)\n",
        "\n",
        "x_train_truck, y_train_truck = prepare_binary_data(x_train, y_train, target_class=9)\n",
        "x_test_truck, y_test_truck = prepare_binary_data(x_test, y_test, target_class=9)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVBHyVfUo_Dd",
        "outputId": "4907ecc3-1ae5-4ac7-a2ec-33088a336139"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tuning ship model on truck vs non-truck images...\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 32ms/step - accuracy: 0.5923 - loss: 0.7014 - val_accuracy: 0.6390 - val_loss: 0.6149 - learning_rate: 0.0044\n",
            "Epoch 2/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 27ms/step - accuracy: 0.6352 - loss: 0.6430 - val_accuracy: 0.6830 - val_loss: 0.5919 - learning_rate: 0.0044\n",
            "Epoch 3/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 28ms/step - accuracy: 0.6429 - loss: 0.6406 - val_accuracy: 0.6795 - val_loss: 0.5941 - learning_rate: 0.0044\n",
            "Epoch 4/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 25ms/step - accuracy: 0.6448 - loss: 0.6388 - val_accuracy: 0.6940 - val_loss: 0.5881 - learning_rate: 0.0044\n",
            "Epoch 5/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 25ms/step - accuracy: 0.6413 - loss: 0.6338 - val_accuracy: 0.6955 - val_loss: 0.5827 - learning_rate: 0.0044\n",
            "Epoch 6/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 27ms/step - accuracy: 0.6372 - loss: 0.6407 - val_accuracy: 0.6865 - val_loss: 0.5801 - learning_rate: 0.0044\n",
            "Epoch 7/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 26ms/step - accuracy: 0.6603 - loss: 0.6237 - val_accuracy: 0.6285 - val_loss: 0.6723 - learning_rate: 0.0044\n",
            "Epoch 8/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 27ms/step - accuracy: 0.6571 - loss: 0.6357 - val_accuracy: 0.6930 - val_loss: 0.5827 - learning_rate: 0.0044\n",
            "Epoch 9/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 26ms/step - accuracy: 0.6578 - loss: 0.6306 - val_accuracy: 0.7055 - val_loss: 0.5780 - learning_rate: 0.0044\n",
            "Epoch 10/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 27ms/step - accuracy: 0.6536 - loss: 0.6322 - val_accuracy: 0.7000 - val_loss: 0.5839 - learning_rate: 0.0044\n",
            "Epoch 11/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 28ms/step - accuracy: 0.6650 - loss: 0.6267 - val_accuracy: 0.6995 - val_loss: 0.5730 - learning_rate: 0.0044\n",
            "Epoch 12/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 27ms/step - accuracy: 0.6553 - loss: 0.6260 - val_accuracy: 0.7020 - val_loss: 0.5751 - learning_rate: 0.0044\n",
            "Epoch 13/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 28ms/step - accuracy: 0.6508 - loss: 0.6330 - val_accuracy: 0.6905 - val_loss: 0.5806 - learning_rate: 0.0044\n",
            "Epoch 14/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6591 - loss: 0.6337\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.00175199992954731.\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 26ms/step - accuracy: 0.6591 - loss: 0.6337 - val_accuracy: 0.6695 - val_loss: 0.5921 - learning_rate: 0.0044\n",
            "Epoch 15/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 27ms/step - accuracy: 0.6650 - loss: 0.6204 - val_accuracy: 0.7105 - val_loss: 0.5657 - learning_rate: 0.0018\n",
            "Epoch 16/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 30ms/step - accuracy: 0.6671 - loss: 0.6153 - val_accuracy: 0.6995 - val_loss: 0.5768 - learning_rate: 0.0018\n",
            "Epoch 17/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 29ms/step - accuracy: 0.6715 - loss: 0.6163 - val_accuracy: 0.7060 - val_loss: 0.5680 - learning_rate: 0.0018\n",
            "Epoch 18/20\n",
            "\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6640 - loss: 0.6254\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0007007999811321497.\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 26ms/step - accuracy: 0.6640 - loss: 0.6254 - val_accuracy: 0.7110 - val_loss: 0.5688 - learning_rate: 0.0018\n",
            "Epoch 19/20\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 28ms/step - accuracy: 0.6724 - loss: 0.6145 - val_accuracy: 0.7085 - val_loss: 0.5652 - learning_rate: 7.0080e-04\n",
            "Epoch 20/20\n",
            "\u001b[1m 647/1250\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 24ms/step - accuracy: 0.6625 - loss: 0.6200"
          ]
        }
      ],
      "source": [
        "model = tf.keras.models.load_model('ship_non_ship_cnn_model.keras')\n",
        "\n",
        "\n",
        "for layer in model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# ---- Unfreeze only the last Conv2D and GlobalAveragePooling2D layers ----\n",
        "# Find last Conv2D\n",
        "last_conv2d = None\n",
        "for layer in reversed(model.layers):\n",
        "    if isinstance(layer, tf.keras.layers.Conv2D):\n",
        "        last_conv2d = layer\n",
        "        break\n",
        "\n",
        "# Find GlobalAveragePooling2D\n",
        "gap_layer = None\n",
        "for layer in model.layers:\n",
        "    if isinstance(layer, tf.keras.layers.GlobalAveragePooling2D):\n",
        "        gap_layer = layer\n",
        "        break\n",
        "\n",
        "if last_conv2d is not None:\n",
        "    last_conv2d.trainable = True\n",
        "if gap_layer is not None:\n",
        "    gap_layer.trainable = True\n",
        "\n",
        "# ---- Recompile ----\n",
        "model.compile(optimizer=RMSprop(learning_rate=4.38e-3, weight_decay=2e-4), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# ---- Fine-tune on automobile vs non-automobile ----\n",
        "\n",
        "\n",
        "def apply_cutout(image, size=8, n_holes=1):\n",
        "    h, w = image.shape[0], image.shape[1]\n",
        "    for n in range(n_holes):\n",
        "        # Random position of cutout\n",
        "        y = np.random.randint(h)\n",
        "        x = np.random.randint(w)\n",
        "\n",
        "        # Ensure cutout stays within image bounds\n",
        "        y1 = np.clip(y - size // 2, 0, h)\n",
        "        y2 = np.clip(y + size // 2, 0, h)\n",
        "        x1 = np.clip(x - size // 2, 0, w)\n",
        "        x2 = np.clip(x + size // 2, 0, w)\n",
        "\n",
        "        # Set the cutout region to zero\n",
        "        image[y1:y2, x1:x2, :] = 0\n",
        "    return image\n",
        "def cutout_preprocess(img):\n",
        "    return apply_cutout(img)\n",
        "datagen = ImageDataGenerator(\n",
        "\n",
        "    rotation_range=12,\n",
        "    width_shift_range=0.10,\n",
        "    height_shift_range=0.14,\n",
        "    zoom_range=0.12,\n",
        "    shear_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    preprocessing_function=apply_cutout\n",
        "\n",
        ")\n",
        "datagen.fit(x_train_truck)\n",
        "\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_loss', patience=4, restore_best_weights=True, verbose=1),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.4, patience=3, verbose=1)\n",
        "]\n",
        "\n",
        "print(\"Fine-tuning ship model on truck vs non-truck images...\")\n",
        "history_truck = model.fit(\n",
        "    datagen.flow(x_train_truck, y_train_truck, batch_size=8),\n",
        "    epochs=20,\n",
        "    validation_data=(x_test_truck, y_test_truck),\n",
        "    callbacks=callbacks,\n",
        "    steps_per_epoch=len(x_train_truck) // 8,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Save final model\n",
        "model.save('truck_non_truck_cnn_model.keras')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CP_eKXxFo_Dd"
      },
      "outputs": [],
      "source": [
        "# prompt: ROC curve of truck non truck model and confusion matrix\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "# Evaluate the fine-tuned model on the test set to get predictions for truck vs non-truck\n",
        "y_pred_prob_truck = model.predict(x_test_truck).ravel()\n",
        "y_pred_class_truck = (y_pred_prob_truck > 0.56).astype(int)\n",
        "\n",
        "# ---- ROC Curve for Truck vs Non-Truck ----\n",
        "fpr_truck, tpr_truck, thresholds_truck = roc_curve(y_test_truck, y_pred_prob_truck)\n",
        "roc_auc_truck = auc(fpr_truck, tpr_truck)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(fpr_truck, tpr_truck, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc_truck)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic for Truck/Non-Truck Classification')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "\n",
        "# ---- Confusion Matrix for Truck vs Non-Truck ----\n",
        "cm_truck = confusion_matrix(y_test_truck, y_pred_class_truck)\n",
        "disp_truck = ConfusionMatrixDisplay(confusion_matrix=cm_truck, display_labels=['Non-Truck', 'Truck'])\n",
        "disp_truck.plot(cmap=plt.cm.Blues)\n",
        "plt.title('Confusion Matrix for Truck/Non-Truck Classification')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}