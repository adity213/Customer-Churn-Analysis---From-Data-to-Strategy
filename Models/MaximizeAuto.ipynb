{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "uKd7IuOWo1j6"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, BatchNormalization, GlobalAveragePooling2D, Input,MaxPool2D, Flatten\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import Adam, SGD,Nadam,AdamW,RMSprop\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.metrics import roc_curve, auc, confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0JvOmrHo1kG",
        "outputId": "377658b5-0dff-4d92-9b50-5883b82f6d3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Load CIFAR-10 data\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# ---- AUTOMOBILE vs NON-AUTOMOBILE ----\n",
        "# Prepare balanced dataset for automobile (class 1) vs non-automobile\n",
        "def prepare_binary_data(x, y, target_class):\n",
        "    pos_idx = np.where(y == target_class)[0]\n",
        "    neg_idx = np.where((y != target_class))[0]\n",
        "    n = min(len(pos_idx), len(neg_idx))\n",
        "    idx = np.concatenate([pos_idx[:n], np.random.choice(neg_idx, n, replace=False)])\n",
        "    np.random.shuffle(idx)\n",
        "    return x[idx].astype('float32') / 255.0, (y[idx] == target_class).astype(int)\n",
        "\n",
        "x_train_auto, y_train_auto = prepare_binary_data(x_train, y_train, target_class=1)\n",
        "x_test_auto, y_test_auto = prepare_binary_data(x_test, y_test, target_class=1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "CiOBMOtgo1kG"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.load_model('ship_non_ship_cnn_model.keras')\n",
        "\n",
        "\n",
        "for layer in model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# ---- Unfreeze only the last Conv2D and GlobalAveragePooling2D layers ----\n",
        "# Find last Conv2D\n",
        "last_conv2d = None\n",
        "for layer in reversed(model.layers):\n",
        "    if isinstance(layer, tf.keras.layers.Conv2D):\n",
        "        last_conv2d = layer\n",
        "        break\n",
        "\n",
        "# Find GlobalAveragePooling2D\n",
        "gap_layer = None\n",
        "for layer in model.layers:\n",
        "    if isinstance(layer, tf.keras.layers.GlobalAveragePooling2D):\n",
        "        gap_layer = layer\n",
        "        break\n",
        "\n",
        "if last_conv2d is not None:\n",
        "    last_conv2d.trainable = True\n",
        "if gap_layer is not None:\n",
        "    gap_layer.trainable = True\n",
        "\n",
        "# ---- Recompile ----\n",
        "model.compile(optimizer=Adam(3.37e-3), loss='binary_crossentropy', metrics=['accuracy'])#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyE1fHo-o1kG",
        "outputId": "bc2cd463-5e5c-4d1d-8249-e3285825ccec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tuning ship model on automobile vs non-automobile images...\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 65ms/step - accuracy: 0.5742 - loss: 0.7376 - val_accuracy: 0.6920 - val_loss: 0.5868 - learning_rate: 0.0034\n",
            "Epoch 2/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 61ms/step - accuracy: 0.6590 - loss: 0.6159 - val_accuracy: 0.6775 - val_loss: 0.5897 - learning_rate: 0.0034\n",
            "Epoch 3/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 61ms/step - accuracy: 0.6619 - loss: 0.6232 - val_accuracy: 0.7220 - val_loss: 0.5639 - learning_rate: 0.0034\n",
            "Epoch 4/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 61ms/step - accuracy: 0.6711 - loss: 0.6157 - val_accuracy: 0.6880 - val_loss: 0.5846 - learning_rate: 0.0034\n",
            "Epoch 5/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 61ms/step - accuracy: 0.6784 - loss: 0.6152 - val_accuracy: 0.7170 - val_loss: 0.5576 - learning_rate: 0.0034\n",
            "Epoch 6/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 60ms/step - accuracy: 0.6694 - loss: 0.6140 - val_accuracy: 0.7315 - val_loss: 0.5552 - learning_rate: 0.0034\n",
            "Epoch 7/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 63ms/step - accuracy: 0.6678 - loss: 0.6129 - val_accuracy: 0.7315 - val_loss: 0.5568 - learning_rate: 0.0034\n",
            "Epoch 8/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 59ms/step - accuracy: 0.6682 - loss: 0.6165 - val_accuracy: 0.7375 - val_loss: 0.5476 - learning_rate: 0.0034\n",
            "Epoch 9/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 59ms/step - accuracy: 0.6729 - loss: 0.6127 - val_accuracy: 0.6970 - val_loss: 0.5698 - learning_rate: 0.0034\n",
            "Epoch 10/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 58ms/step - accuracy: 0.6720 - loss: 0.6003 - val_accuracy: 0.7330 - val_loss: 0.5659 - learning_rate: 0.0034\n",
            "Epoch 11/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.6683 - loss: 0.6186\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0016850000247359276.\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 59ms/step - accuracy: 0.6683 - loss: 0.6186 - val_accuracy: 0.7245 - val_loss: 0.5548 - learning_rate: 0.0034\n",
            "Epoch 12/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 60ms/step - accuracy: 0.6737 - loss: 0.6045 - val_accuracy: 0.7175 - val_loss: 0.5606 - learning_rate: 0.0017\n",
            "Epoch 13/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 61ms/step - accuracy: 0.6677 - loss: 0.6052 - val_accuracy: 0.7050 - val_loss: 0.5710 - learning_rate: 0.0017\n",
            "Epoch 13: early stopping\n",
            "Restoring model weights from the end of the best epoch: 8.\n"
          ]
        }
      ],
      "source": [
        "# ---- Fine-tune on automobile vs non-automobile ----\n",
        "\n",
        "\n",
        "def apply_cutout(image, size=8, n_holes=1):\n",
        "    h, w = image.shape[0], image.shape[1]\n",
        "    for n in range(n_holes):\n",
        "        # Random position of cutout\n",
        "        y = np.random.randint(h)\n",
        "        x = np.random.randint(w)\n",
        "\n",
        "        # Ensure cutout stays within image bounds\n",
        "        y1 = np.clip(y - size // 2, 0, h)\n",
        "        y2 = np.clip(y + size // 2, 0, h)\n",
        "        x1 = np.clip(x - size // 2, 0, w)\n",
        "        x2 = np.clip(x + size // 2, 0, w)\n",
        "\n",
        "        # Set the cutout region to zero\n",
        "        image[y1:y2, x1:x2, :] = 0\n",
        "    return image\n",
        "def cutout_preprocess(img):\n",
        "    return apply_cutout(img)\n",
        "x_train_auto_cutout = x_train_auto.copy()\n",
        "for i in range(len(x_train_auto_cutout)):\n",
        "    x_train_auto_cutout[i] = apply_cutout(x_train_auto_cutout[i])\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    preprocessing_function=cutout_preprocess,\n",
        "    rotation_range=6,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "datagen.fit(x_train_auto_cutout)\n",
        "\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1)\n",
        "]\n",
        "\n",
        "print(\"Fine-tuning ship model on automobile vs non-automobile images...\")\n",
        "history_auto = model.fit(\n",
        "    datagen.flow(x_train_auto_cutout, y_train_auto, batch_size=16),\n",
        "    epochs=20,\n",
        "    validation_data=(x_test_auto, y_test_auto),\n",
        "    callbacks=callbacks,\n",
        "    steps_per_epoch=len(x_train_auto_cutout) // 16,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Save final model\n",
        "model.save('auto_non_auto_cnn_model_from_ship.keras')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2lhEO6Mfo1kH"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}